{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get countries and make regexes out of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geonamescache\n",
    "import re\n",
    "import unidecode\n",
    "gc = geonamescache.GeonamesCache()\n",
    "\n",
    "gc_countries = gc.get_countries()\n",
    "countries = list(gc_countries.values())\n",
    "for country in countries:\n",
    "    country['@manning/type'] = 'country'\n",
    "    country['@manning/decoded_name'] = unidecode.unidecode(country['name'])\n",
    "\n",
    "country_res = [re.compile('\\\\b{}\\\\b'.format(country['@manning/decoded_name']), flags=re.IGNORECASE) for country in countries]\n",
    "country_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get cities and make regexes out of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geonamescache\n",
    "import re\n",
    "import unidecode\n",
    "gc = geonamescache.GeonamesCache()\n",
    "\n",
    "gc_cities = gc.get_cities()\n",
    "cities = list(gc_cities.values())\n",
    "for city in cities:\n",
    "    city['@manning/type'] = 'city'\n",
    "    city['@manning/decoded_name'] = unidecode.unidecode(city['name'])\n",
    "\n",
    "city_res = [re.compile('\\\\b{}\\\\b'.format(city['@manning/decoded_name']), flags=re.IGNORECASE) for city in cities]\n",
    "city_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all US states and make regexes out of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geonamescache\n",
    "import re\n",
    "import unidecode\n",
    "gc = geonamescache.GeonamesCache()\n",
    "\n",
    "gc_us_states = gc.get_us_states()\n",
    "us_states = list(gc_us_states.values())\n",
    "for us_state in us_states:\n",
    "    us_state['@manning/type'] = 'us_state'\n",
    "    us_state['@manning/decoded_name'] = unidecode.unidecode(us_state['name'])\n",
    "\n",
    "us_state_res = [re.compile('\\\\b{}\\\\b'.format(us_state['@manning/decoded_name']), flags=re.IGNORECASE) for us_state in us_states]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all US counties and make regexes out of them\n",
    "#### Check if county ends with ' County' - if so regex for county X should be r'\\b(X County|X)\\b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geonamescache\n",
    "import re\n",
    "import unidecode\n",
    "gc = geonamescache.GeonamesCache()\n",
    "\n",
    "us_counties = gc.get_us_counties()\n",
    "for us_county in us_counties:\n",
    "    us_county['@manning/type'] = 'us_county'\n",
    "    us_county['@manning/decoded_name'] = unidecode.unidecode(us_county['name'])\n",
    "\n",
    "us_county_res = list()\n",
    "for county_dict in us_counties:\n",
    "    if county_dict['@manning/decoded_name'][-7:] == ' County':\n",
    "        us_county_res.append(re.compile('\\\\b({}|{})\\\\b'.format(county_dict['@manning/decoded_name'], county_dict['@manning/decoded_name'][:-7]), flags=re.IGNORECASE))\n",
    "    else:\n",
    "        us_county_res.append(re.compile('\\\\b{}\\\\b'.format(county_dict['@manning/decoded_name']), flags=re.IGNORECASE))\n",
    "\n",
    "us_county_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get headlines in list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import unidecode\n",
    "\n",
    "headlines_path = os.path.join('..', 'data', 'headlines.txt')\n",
    "headlines_file = open(headlines_path, \"r\")\n",
    "headlines_str = headlines_file.read()\n",
    "headlines_list = [unidecode.unidecode(headline.strip()) for headline in headlines_str.split('\\n')]\n",
    "headlines_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a factory to avoid repeating same logic to match with various regexes\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_line_factory(regex_list, associated_list):\n",
    "    def match_line(line):\n",
    "        matches = list()\n",
    "        for i in range(len(regex_list)):\n",
    "            regex = regex_list[i]\n",
    "            match = regex.search(line)\n",
    "            if match: matches.append({\n",
    "                'headline': line,\n",
    "                'match': match,\n",
    "                'regex': regex,\n",
    "                'src_data': associated_list[i],\n",
    "                'weight': 0\n",
    "            })\n",
    "        return matches\n",
    "    return match_line\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Match each line in headlines with the various regexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_country = match_line_factory(country_res, countries)\n",
    "match_city = match_line_factory(city_res, cities)\n",
    "match_us_state = match_line_factory(us_state_res, us_states)\n",
    "match_us_county = match_line_factory(us_county_res, us_counties)\n",
    "\n",
    "country_matches = list()\n",
    "city_matches = list()\n",
    "us_state_matches= list()\n",
    "us_county_matches = list()\n",
    "headline_to_all_matches = {}\n",
    "for line in headlines_list:\n",
    "    country_matches_for_line = match_country(line)\n",
    "    if len(country_matches_for_line): country_matches.extend(country_matches_for_line)\n",
    "    city_matches_for_line = match_city(line)\n",
    "    if len(city_matches_for_line): city_matches.extend(city_matches_for_line)\n",
    "    us_state_match_for_line = match_us_state(line)\n",
    "    if len(us_state_match_for_line): us_state_matches.extend(us_state_match_for_line)\n",
    "    us_county_match_for_line = match_us_county(line)\n",
    "    if len(us_county_match_for_line): us_county_matches.extend(us_county_match_for_line)\n",
    "    headline_to_all_matches[line] = country_matches_for_line + city_matches_for_line + us_state_match_for_line + us_county_match_for_line\n",
    "\n",
    "data = {}\n",
    "data['country_matches'] = country_matches\n",
    "data['city_matches'] = city_matches\n",
    "data['us_state_matches'] = us_state_matches\n",
    "data['us_county_matches'] = us_county_matches\n",
    "data['all'] = headline_to_all_matches\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 'Zika Outbreak Hits Miami' headline\n",
    "\n",
    "Matches:\n",
    "- 'Miami' city\n",
    "- 'Miami' us_county state 'IN'\n",
    "- 'Miami' us_county state 'KS\n",
    "- 'Miami' us_county state 'OH\n",
    "\n",
    "See below for example of how to inspect matches for headline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = data['all']['Zika Outbreak Hits Miami']\n",
    "# same:\n",
    "# matches = list(data['all'].values())[0]\n",
    "\n",
    "assert(len(matches) == 4)\n",
    "matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some functions to weed out results\n",
    "\n",
    "`zero_out_weights` resets teh weights on matches\n",
    "\n",
    "`reward_longest_name` adds weight to longest name match (but ignores matches with ' County' in them as I think they arbitrarily inflate length). Also, counties don't seem to be that important here.\n",
    "\n",
    "`reward_cities` as if you have a country and a city, city will have more info: the city, and the countrycode. If it's a country, you won't get the city. And because city only has countrycode (no country name), I'm only going for country['iso'] if I ever need to extract from country. Also the reward for cities should be greater than that of longest name as if you get a country with a longer name, you want the city to win."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "county_re = re.compile(r' County', flags=re.IGNORECASE)\n",
    "\n",
    "def zero_out_weights(list_of_matches):\n",
    "    for match in list_of_matches: match['weight'] = 0\n",
    "\n",
    "\n",
    "def reward_longest_name(list_of_matches):\n",
    "    longest_name_length = 0\n",
    "    match_with_longest_name = None\n",
    "    for match in list_of_matches:\n",
    "        match_name = match['src_data']['name']\n",
    "        # skip names with ' County':\n",
    "        if county_re.search(match_name): continue\n",
    "        match_name_length = len(match_name)\n",
    "        if (match_name_length > longest_name_length):\n",
    "            longest_name_length = match_name_length\n",
    "            match_with_longest_name = match\n",
    "    if match_with_longest_name: match_with_longest_name['weight'] += 1\n",
    "    return list_of_matches\n",
    "\n",
    "\n",
    "def reward_cities(list_of_matches):\n",
    "    for match in list_of_matches:\n",
    "        if match['src_data']['@manning/type'] == 'city':\n",
    "            match['weight'] += 2\n",
    "\n",
    "def get_best_match(list_of_matches = []):\n",
    "    return max(list_of_matches, key = lambda match: match['weight'])\n",
    "    \n",
    "    \n",
    "# list_of_matches = list(data['all'].values())[1]\n",
    "# zero_out_weights(list_of_matches)\n",
    "# reward_longest_name(list_of_matches)\n",
    "\n",
    "# get_best_match(list_of_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_list_of_matches = list(data['all'].values())\n",
    "\n",
    "df_dict = {}\n",
    "df_dict['headline_col'] = list()\n",
    "df_dict['city_col'] = list()\n",
    "df_dict['country_col'] = list()\n",
    "\n",
    "for list_of_matches in list_of_list_of_matches:\n",
    "    if len(list_of_matches):\n",
    "        zero_out_weights(list_of_matches)\n",
    "        reward_longest_name(list_of_matches)\n",
    "        reward_cities(list_of_matches)\n",
    "        best_match = get_best_match(list_of_matches)\n",
    "        if best_match['src_data']['@manning/type'] == 'city':\n",
    "            df_dict['headline_col'].append(best_match['headline'])\n",
    "            df_dict['city_col'].append(best_match['src_data']['name'])\n",
    "            df_dict['country_col'].append(best_match['src_data']['countrycode'])\n",
    "        elif best_match['src_data']['@manning/type'] == 'country':\n",
    "    #         since in city there's only countrycode, I'm taking iso here:\n",
    "            df_dict['headline_col'].append(best_match['headline'])\n",
    "            df_dict['city_col'].append(float('nan'))\n",
    "            df_dict['country_col'].append(best_match['src_data']['iso'])\n",
    "        elif best_match['src_data']['@manning/type'] == 'us_state':\n",
    "    #         there is no city so go for state instead (location / surrounding area will include city...)\n",
    "            df_dict['headline_col'].append(best_match['headline'])\n",
    "            df_dict['city_col'].append(best_match['src_data']['name'])\n",
    "            df_dict['country_col'].append('US')\n",
    "        elif best_match['src_data']['@manning/type'] == 'us_county':\n",
    "    #         there is no city so go for county instead (location / surrounding area will include city...)\n",
    "            df_dict['headline_col'].append(best_match['headline'])\n",
    "            df_dict['city_col'].append(best_match['src_data']['name'])\n",
    "            df_dict['country_col'].append('US')\n",
    "        \n",
    "\n",
    "# df_dict\n",
    "(len(df_dict['headline_col']), len(df_dict['city_col']), len(df_dict['country_col']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deliverable chapter 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'headline': df_dict['headline_col'], 'city': df_dict['city_col'], 'country': df_dict['country_col'] })\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
